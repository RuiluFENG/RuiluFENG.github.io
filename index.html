---
layout: page
---

<div class="grid">
  <img class="header-img" src="/assets/images/Jinchao.png" alt="Photo" align="left">
  <div class="header-text">
    <h2 style="margin-top: 0 !important;">Jinchao Li</h2>
    Ph.D. Candidate, <a href="https://www.se.cuhk.edu.hk/laboratories/human-computer-communications-laboratory/" target="_blank">HCCL Lab</a><br>
    <a href="https://cuhk.edu.hk" target="_blank">The Chinese University of Hong Kong</a><br>
    Hong Kong, China<br>
    Email: jcli [at] se.cuhk.edu.hk<br>
    <div>{%- include author-links.html author=site.author -%}</div>
  </div>
</div>

<div class="home__content">
  <h3 id="bio">Short Bio</h3>  
    <div class="body-text">
    <p>Jinchao Li is a Ph.D. candidate at <a href="https://www.se.cuhk.edu.hk/laboratories/human-computer-communications-laboratory/" target="_blank">
    Human-Computer Communications Laboratory</a> in <a href="https://cuhk.edu.hk" target="_blank">The Chinese University of Hong Kong</a>, 
    advised by Prof. <a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/" target="_blank">Helen Meng</a>.
    He got the B.S. of Acoustics from Physics Department, <a href="https://www.nju.edu.cn" target="_blank">Nanjing University</a> in 2019.
    He is interested in <span style="font-weight: bold;">neurocognitive disorder detection</span>, 
    and <span style="font-weight: bold;">speech and language processing</span>.
    </p></div>

  <h3 id="publications">Publications</h3>  
    <div class="grid">
      <div class="body-img">
        <a href="{{site.url}}/assets/papers/Comp_AD.png" target="_blank"><img src="/assets/papers/Comp_AD8.png"></a>
      </div>
      <div class="body-text">
        <span style="font-weight: bold;">[1] A Comparative Study of Acoustic and Linguistic Features Classification for Alzheimer's Disease Detection</span><br>
        <span style="font-weight: bold;">Jinchao Li</span>, Jianwei Yu, Zi Ye, Simon Wong, Manwai Mak, Brian Mak, Xunying Liu, Helen Meng<br>
        IEEE International Conference on Acoustics, Speech, & Signal Processing (<span style="font-weight: bold;">ICASSP</span>), 2021<br>
        <span class="tag"><a href="https://ieeexplore.ieee.org/abstract/document/9414147" target="_blank">[Paper]</a></span>
        <span class="tag"><a href="/assets/papers/Comp_AD.pdf" target="_blank"> [Poster]</a></span>
      </div>
    </div>

    <div class="grid">
      <div class="body-img">
        <a href="{{site.url}}/assets/papers/ASR_AD.png" target="_blank"><img src="/assets/papers/ASR_AD8.png"></a>
      </div>
      <div class="body-text">
        <span style="font-weight: bold;">[2] Development of The CUHK Elderly Speech Recognition System for Neurocognitive Disorder Detection Using the Dementiabank Corpus</span><br>
        Zi Ye, Shoukang Hu, <span style="font-weight: bold;">Jinchao Li</span>, Xurong Xie, Mengzhe Geng, Jianwei Yu, Junhao Xu, Boyang Xue, Shansong Liu, Xunying Liu, Helen Meng<br>
        IEEE International Conference on Acoustics, Speech, & Signal Processing (<span style="font-weight: bold;">ICASSP</span>), 2021<br>
        <span class="tag"><a href="https://ieeexplore.ieee.org/abstract/document/9413634" target="_blank">[Paper]</a>
        </span>
        <span class="tag"><a href="/assets/papers/ASR_AD.pdf" target="_blank">[Poster]</a>
        </span>
      </div>
    </div>

    <div class="grid">
      <div class="body-img" style="margin-top: 0.5rem;">
        <a href="{{site.url}}/assets/papers/SC.png" target="_blank"><img src="/assets/papers/SC8.png"></a>
      </div>
      <div class="body-text">
        <span style="font-weight: bold;">[3] Method, Device and Electronic Equipment for Determining Sound Source Information based on Microphone Array</span><br>
        <span style="font-weight: bold;">Jinchao Li</span>, Changbao Zhu<br>
        <span style="font-weight: bold;">Patent</span>: CN110148422B, 2021<br>
      </div>
    </div>

    <div class="grid">
      <div class="body-img">
        <a href="{{site.url}}/assets/papers/mie.jpg" target="_blank"><img src="/assets/papers/mie8.jpg"></a>
      </div>
      <div class="body-text" style="margin-bottom: 0;">
        <span style="font-weight: bold;">[4] Acoustic Mie Resonance and its application</span><br>
        <span style="font-weight: bold;">Jinchao Li</span>, Jin Zhang, Ying Cheng, Xiaojun Liu<br>
        <span style="font-weight: bold;">Physics</span> 46(11): 731-739, 2017<br>
        <span class="tag"><a href="http://www.wuli.ac.cn/CN/Y2017/V46/I11/731" target="_blank">[Paper]</a>
        </span>
      </div>
    </div>


  <h3 id="research">Research Experience</h3>
    <div class="grid">
      <div class="body-img2">
        <a href="https://www.cuhk.edu.hk" target="_blank"><img src="/assets/images/cuhk.png"></a>
      </div>
      <div class="body-text">
        <table width="100%" cellspacing="0" cellpadding="0">
          <tbody>
            <tr><td style="font-weight: bold;">Neurocognitive Disorder Detection</td>
              <td align='right' > Jul.2020 - Now </td></tr>
            <tr><td>
              Advised by Prof. <a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/" target="_blank">Helen Meng</a> 
              and Prof. <a href="https://www1.se.cuhk.edu.hk/~xyliu/" target="_blank">Xunying Liu</a>
              @HCCL, CUHK
            </td>
              <td align='right' > Hong Kong S.A.R. </td></tr>
          </tbody>
        </table>

          <li>Speech and language based Neurocognitive Disorder (NCD) detection.
          <li>Comparative study of acoustic and linguistic features for NCD detection, published on ICASSP 2021.
          <li>Elderly speech recognition for NCD detection, published on ICASSP 2021.
          </li>
      </div>
    </div>

    <div class="grid">
      <div class="body-img2">
        <a href="http://www.speechx.cn" target="_blank"><img src="/assets/images/speechx.png"></a>
      </div>
      <div class="body-text">
        <table width="100%" cellspacing="0" cellpadding="0">
          <tbody>
            <tr><td style="font-weight: bold;">Multi-modal Speech Enhancement</td>
              <td align='right' > Dec.2019 - Jan.2020 </td></tr>
            <tr><td>Advised by Dr. <a href="https://scholar.google.com.hk/citations?user=_8NTKIwAAAAJ&hl=en" target="_blank">Kun Li</a>
              @SpeechX</td>
              <td align='right' > Shenzhen, China </td></tr>
          </tbody>
        </table>
          <li>Audio-visual speech enhancement for both magnitude and phase.<br>
          <li>Achieved decreasing of WER from 90% to 10% under two-speaker noisy scenarios.
          </li>
      </div>
    </div>

    <div class="grid">
      <div class="body-img2">
        <a href="https://www.horizon.ai" target="_blank"><img src="/assets/images/horizonai.png"></a>
      </div>
      <div class="body-text" style="margin-bottom: 0;">
        <table width="100%" cellspacing="0" cellpadding="0">
          <tbody>
            <tr><td style="font-weight: bold;">Source Counting</td>
              <td align='right' > Dec.2018 - Apr.2019 </td></tr>
            <tr><td>
              Advised by Prof. <a href="https://physics.nju.edu.cn/sz/skxygcx/20190904/i18734.html" target="_blank">Jing Lu</a>
              @NJU and Mr. <a href="https://www.linkedin.com/in/长宝-朱-a9b778b6/" target="_blank">Changbao Zhu</a> @Horizon Robotics
            </td>
              <td align='right' > Nanjing, China </td></tr>
          </tbody>
        </table>
          <li>Binaural speech source counting in reverberated and noisy scenarios.<br>
          <li>Achieved over 90% counting accuracy under up to 5 speakers overlapping scenarios.
          <li>Honored the "Excellent Undergraduate Thesis" in NJU, 2019. Published a patent in 2021.
          </li>
      </div>
    </div>


  <h3 id="awards">Honors & Awards</h3>
    <div class="grid">
      <div class="body-text" style="margin-bottom: 0;">
        <table width="100%">
          <tbody>
            <tr><td><li>National Scholarship, awarded by the Ministry of Education in China </td> <td align="right"> 2017 </td></tr>
            <tr><td><li>Excellent Undergraduate Thesis of Nanjing University </td> <td align="right"> 2019 </td></tr>
            <tr><td><li>Meritorious winner prize in National Mathematical Contest in Modeling, top 1.5% in China </td> <td align="right"> 2017 </td></tr>
            <tr><td><li>Meritorious winner prize in American Mathematical Contest in Modeling </td> <td align="right"> 2018 </td></tr>
            <tr><td><li>First Prize, Elite Program Scholarship of Nanjing University </td> <td align="right"> 2016 </td></tr>
            <tr><td><li>Shan Yuan Overseas Exchange Scholarship of Nanjing University </td> <td align="right"> 2017 </td></tr>
            <tr><td><li>People Scholarship of Nanjing University </td> <td align="right"> 2018 </td></tr>
            </li>
          </tbody>
        </table>
      </div>
    </div>

  <h3 id="miscellaneous">Miscellaneous</h3>
    <div class="grid">
      <div class="body-text" style="margin-bottom: 0;">
        <!-- <details><summary>Click to expand</summary> -->
        <span style="font-weight: bold;">Volunteer and Leadership Experience</span><br>
          <li>Worked as team leader in NCMMSC2021 - Chinese Alzheimer’s Disease Recognition Competition, 2021.<br>
          <li>Worked as team leader in American Mathematical Contest in Modeling, 2018.<br>
          <li>Organized a rural education research in Jiangxi Province to investigate and call for more attention to rural children's growth and education. Honored the "Top Ten Teams of Social Practice" in NJU, 2016.<br>
          <li>Volunteered in psychological consulting with elderly people, folk-art teaching to primary school students, etc.<br>
          </li>
        <span style="font-weight: bold;">Computer Competencies</span>
        <p>Python, MATLAB, Shell, TensorFlow, PyTorch, Kaldi</p>
        <!-- </details> -->
      </div>
    </div>
</div> 


<!-- <div style="text-align:center;">
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=2d78ad&w=250&t=tt&d=NoxTntTwijcGNPPsm7CM_ctT1E79_SAsBke-aS4Vw4Q&co=ffffff&ct=2d78ad&cmo=aa3939&cmn=ff5353'></script>
</div> -->

<script>
{%- include scripts/article.js -%}
</script>
