
<!-- <div align=center>
<img width="500" src="img/cover.png" alt="封面"/>
</div> -->

本项目参考[《动手学深度学习》](http://d2l.ai/)（原书作者：阿斯顿·张、李沐、扎卡里 C. 立顿、亚历山大 J. 斯莫拉以及其他社区贡献者）及有关PyTorch[实现项目](https://tangshusen.me/Dive-into-DL-PyTorch)。

## 简介
本项目主要包含深度学习、自然语言处理有关知识的介绍，以及一些经典文章的分享。欢迎对本项目做出贡献或提出issue。

## 面向人群
对深度学习、自然语言处理等相关领域感兴趣的童鞋。

## 目录
- [ ] 数学基础
  - [ ] 线性代数: 矩阵乘法、求导、链式法则、误差逆传播
  - [ ] 支持向量机
  - [ ] 朴素贝叶斯
- [ ] 神经网络
  - [ ] 多层感知机
  - [ ] 卷积神经网络
  - [ ] 循环神经网络
  - [ ] 残差神经网络
  - [ ] 时延神经网络
  - [ ] 贝叶斯网络
  - [ ] 生成对抗性网络
- [ ] 注意力机制
  - [ ] 自注意力、多头注意力和位置编码
  - [ ] Transformer
  - [ ] Conformer
- [ ] 优化算法
  - [ ] 优化
  - [ ] SGD, Adam
  - [ ] 学习率调度器
- [ ] 预训练
  - [ ] 嵌入
  - [ ] 来自Transformers的双向编码器表示（BERT）
  - [ ] 预训练BERT
  - [ ] RoBERTa
  - [ ] Wav2Vec 2.0
  - [ ] HuBERT
- [ ] 推理
  - [ ] 使用注意力
  - [ ] 微调BERT
- [ ] 自适应
  - [ ] 说话人自适应
  - [ ] 域自适应
- [ ] 语音识别
  - [ ] GMMM-HMM
  - [ ] CTC损失函数
- [ ] 其他
  - [ ] 多模态学习
  - [ ] 多任务学习
  - [ ] 对比学习
  - [ ] 元学习
  - [ ] Seq2Seq学习

持续更新中......

## 原书地址
中文版：[动手学深度学习](https://zh.d2l.ai/) | [Github仓库](https://github.com/d2l-ai/d2l-zh)       
English Version: [Dive into Deep Learning](https://d2l.ai/) | [Github Repo](https://github.com/d2l-ai/d2l-en)


## 引用
如果您在研究中使用了这个项目请引用原书:
```
@book{zhang2019dive,
    title={Dive into Deep Learning},
    author={Aston Zhang and Zachary C. Lipton and Mu Li and Alexander J. Smola},
    note={\url{http://www.d2l.ai}},
    year={2020}
}
```
